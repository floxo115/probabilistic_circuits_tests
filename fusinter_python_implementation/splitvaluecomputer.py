import numpy as np
from numba import jit

from .orderedheap_with_references import OrderedHeap


def shannon_entropy(input_column: np.ndarray, alpha, lam, m, n) -> float:
    """
    Implementation of the Shannon Entropy for one column formula on page 12 of the paper
    :param input_column: a numpy array in the form of a column generated by FUSINTER
    :param alpha: a scalar weight parameter (see the paper)
    :param lam: a scalar weight parameter (see the paper)
    :m: the number of classes
    :n: sum of all components of the table where column is from
    :return: a scalar value for estimation splits
    """
    col_sum = 0
    n_j = np.sum(input_column)
    col_fac = alpha * n_j / n
    for i in range(m):
        p = (input_column[i] + lam) / (n_j + m * lam)
        col_sum += -(p * np.log2(p))
    result = col_fac * col_sum + (1 - alpha) * m * lam / n_j

    return result


class SplitValueComputer:
    def __init__(self, table: np.ndarray, split_points: np.ndarray, alpha: float, lam: float):
        assert alpha > 0
        assert lam > 0

        self.table = table
        self.alpha = alpha
        self.lam = lam

        # compute necessary values for updating the split values
        self.m = table.shape[0]
        self.k = table.shape[1]
        self.n = np.sum(table)
        self.entropy_func = lambda x: shannon_entropy(x, self.alpha, self.lam, self.m, self.n)

        self.heap = OrderedHeap()

        for col_idx in range(table.shape[1] - 1):
            data = {
                "split_point": split_points[col_idx],
                "left_column": col_idx,
                "right_column": col_idx + 1,
            }
            self.heap.insert_element(
                [self.compute_delta(table[:, col_idx], table[:, col_idx + 1]), -col_idx],
                data,
            )

        self.heap.build_heap()

    def compute_delta(self, column1: np.ndarray, column2: np.ndarray):
        delta = 0.
        delta += self.entropy_func(column1)
        delta += self.entropy_func(column2)
        delta -= self.entropy_func(column1 + column2)

        return delta

    def get_max_delta(self):
        return self.heap.array[0].sort_values[0]

    def merge_max(self):
        if len(self.heap) == 0:
            raise Exception("the heap is already empty")

        max_element = self.heap.array[0]
        left_neighbor = None
        right_neighbor = None

        if max_element.previous:
            left_neighbor = self.heap.array[max_element.previous.pos]

        if max_element.next:
            right_neighbor = self.heap.array[max_element.next.pos]

        merged_column = self.table[:, max_element.data["left_column"]] + self.table[:, max_element.data["right_column"]]
        self.table[:, max_element.data["left_column"]] = merged_column

        self.heap.delete_max()

        if left_neighbor:
            new_sort_values = [self.compute_delta(self.table[:, left_neighbor.data["left_column"]],
                                                     self.table[:,left_neighbor.data["right_column"]]), left_neighbor.sort_values[1]]
            self.heap.update_node(new_sort_values, left_neighbor.pos)

        if right_neighbor:
            right_neighbor.data["left_column"] = max_element.data["left_column"]
            new_sort_values = [self.compute_delta(self.table[:,right_neighbor.data["left_column"]],
                                                      self.table[:,right_neighbor.data["right_column"]]), right_neighbor.sort_values[1]]
            self.heap.update_node(new_sort_values, right_neighbor.pos)


    def get_splits(self):
        splits = []
        for el in self.heap.array:
            splits.append(el.data["split_point"])

        splits.sort()
        return splits
